{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "20b30ca4-1add-4f24-affe-6371c84fbb39",
   "metadata": {},
   "source": [
    "# IRRmodel\\*WCM calibration with PSO on KGE of $\\sigma^0$\n",
    "\n",
    "The v5 code is a final, cleaned and commented version.\n",
    "\n",
    "## Temporal resolution of inputs parameters and calibration\n",
    "The input datasets can have different temporal resolutions:\n",
    "- hourly\n",
    "- daily\n",
    "- multi-daily\n",
    "\n",
    "platinum_df tables of Budrio's SWC, rain and irrigation are hourly.\n",
    "Climate data such as ET and PET are daily. \n",
    "Sigma0 values are daily and multi-daily.\n",
    "NDVI, LAI and other satellite products are multi-daily.\n",
    "\n",
    "In order to be self-consistent, the model must be calibrated by taking\n",
    "into account the temporal scale of variation of quantities.\n",
    "In particular, the soil water balance (SWB) model requires inputs\n",
    "that can be hourly or daily. Hourly data have to resampled to be\n",
    "consistent with daily ones, so SWC, rain and irrigation have to be taken\n",
    "as their mean and sum values. In this way consistency with ET or PET is\n",
    "ensured.\n",
    "Once the SWB model has provided daily values, they can be used as inputs in\n",
    "the water cloud model, that is calibrated against sigma0 values.\n",
    "\n",
    "It is clear that an optimal calibration would require an hourly SWB estimate\n",
    "to match with the correct hours of passage of the satellite. On the other\n",
    "hand, this would require hourly interpolation of ET and PET data. Moreover, at the\n",
    "moment the computational power required for such a procedure is not possible\n",
    "to estimate."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "7bf409eb-8332-4bd8-adc3-c96f31d066e2",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.append('../')\n",
    "\n",
    "from modules.funcs import *\n",
    "from modules.funcs_pso import *\n",
    "# from modules.pyeto import *\n",
    "\n",
    "# KEEP YOUR MODELS IN THE NOTEBOOK UNTIL THEY ARE PERFECT\n",
    "# CAUSE EXTERNAL IMPORT IS AWFUL IN JUPYTER\n",
    "# from IRRI_WCM.IRRI_WCM_model import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "897c8532-64f7-4e3a-a324-6d286a3dceec",
   "metadata": {},
   "outputs": [],
   "source": [
    "def pso_calib_irri(PAR):\n",
    "    \"\"\"Ausiliary function for PSO optimization\"\"\"\n",
    "    global inputs\n",
    "    global irri\n",
    "    n_particles = PAR.shape[0]\n",
    "    err = np.zeros(n_particles)\n",
    "    for i in range(n_particles):\n",
    "        WW,IRR,sig0,KGE = IRR_WCM(PAR[i], inputs, irri)\n",
    "        err[i] = 1 - KGE\n",
    "    return err"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5fd49fd0-ea3e-4908-a815-4728cdbba64b",
   "metadata": {},
   "source": [
    "# WCM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "834cc7cb-22a0-4e73-9b17-8f611856c6b0",
   "metadata": {},
   "outputs": [],
   "source": [
    "def WCM(PAR, data_in, units='lin'):\n",
    "    \"\"\"Water Cloud Model.\n",
    "    \n",
    "    This function simulates backscattering with WCM and returns\n",
    "    the KGE index to perform its minimization for calibration\n",
    "    of parameters A,B,C,D.\n",
    "    WCM is parametrized with a single vegetation descriptor (nominated\n",
    "    LAI, but can be anything).\n",
    "    Fitting can be performed in linear or dB scale.\n",
    "    \n",
    "    \n",
    "    Inputs\n",
    "    ------\n",
    "    - PAR: list\n",
    "        List of initial guesses for the parameters to calibrate.\n",
    "    - data_in: list\n",
    "        List of inputs of observables, that must be in the form:\n",
    "        [SM,LAI,t_deg,obs], being SM = soil moisture,\n",
    "        LAI = Leaf Area Index, t_deg = angle of observation,\n",
    "        obs = observed total sigma0\n",
    "    - units: str, default 'linear'\n",
    "        choose to calibrate the model's parameters in 'linear' or 'db' scale\n",
    "        \n",
    "    Return\n",
    "    ------\n",
    "    KGE between simulated and observed backscattering.\n",
    "    \n",
    "    \"\"\"\n",
    "\n",
    "    A,B,C,D = PAR # parameters to fit\n",
    "    SM,LAI,t_deg,obs = data_in # input data\n",
    "    \n",
    "    theta = t_deg*np.pi/180. # angle of observation\n",
    "    sig0s_dB = C+D*SM # sigma0_soil [dB]\n",
    "    T2 = np.exp((-2*B*LAI)/np.cos(theta)) # attenuation\n",
    "    \n",
    "    if units=='lin':\n",
    "        sig0s = db_lin(sig0s_dB) # sigma0_soil [lin]\n",
    "        sig0v = A*LAI*np.cos(theta)*(1-T2) # sigma0_veg [lin]\n",
    "        sig0_lin = T2*sig0s+sig0v # sigma0_tot [lin]\n",
    "        sig0=lin_db(sig0_lin) # sigma0_tot [dB]\n",
    "    elif units=='db':\n",
    "        sig0v = A*LAI*np.cos(theta)*(1-T2) # sigma0_veg [db]\n",
    "        sig0 = T2*sig0s+sig0v # sigma0_tot [db]\n",
    "    else: raise NameError('Please choose one of the options: linear/db')\n",
    "        \n",
    "    OUT=he.evaluator(he.kge, sig0, obs) # OUT is kge, r, alpha, beta\n",
    "    KGE=OUT[0,:];\n",
    "\n",
    "    return [sig0,KGE]\n",
    "\n",
    "#----------------------------------------------------------------------------\n",
    "\n",
    "def SM_fromWCM(PAR, data_in, units='lin'):\n",
    "    \"\"\"Inverted WCM for SM estimation.\"\"\"\n",
    "\n",
    "    A,B,C,D = PAR # parameters, fitted\n",
    "    SM,LAI,t_deg,obs = data_in # input data\n",
    "    \n",
    "    theta = t_deg*np.pi/180. # angle of observation\n",
    "    T2 = np.exp((-2*B*LAI)/np.cos(theta)) # attenuation\n",
    "    sig0v = A*LAI*np.cos(theta)*(1-T2) # sigma0_veg\n",
    "    \n",
    "    if units=='lin':\n",
    "        sig0s_lin = (db_lin(obs)-sig0v)/T2\n",
    "        SMretr = (lin_db(sig0s_lin)-C)/D\n",
    "    elif units=='db':\n",
    "        sig0s = (obs-sig0v)/T2\n",
    "        SMretr = (sig0s-C)/D \n",
    "    \n",
    "    OUT=he.evaluator(he.kge, SMretr, SM) # OUT is kge, r, alpha, beta\n",
    "    KGE=OUT[0,:];\n",
    "\n",
    "    return [SMretr,KGE]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "03fc0993-11dd-47c2-b7ae-ec776880402d",
   "metadata": {},
   "source": [
    "# IRRI+WCM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "53bcb3ff-0fe0-4f31-817a-463be1e29031",
   "metadata": {},
   "outputs": [],
   "source": [
    "def IRR_WCM(PAR, inputs, user_in):\n",
    "    \"\"\"Irrigation model and WCM integration.\n",
    "    \n",
    "    Based on minimization of KGE between observed and simulated\n",
    "    $\\sigma^0$ values via PSO (pyswarm) optimization.\n",
    "    The soil water balance model (IRR) produces an estimate of the soil water\n",
    "    content WW [%] that is used to simulate $\\sigma^0$ by a water cloud\n",
    "    model (WCM).\n",
    "    \n",
    "    Inputs\n",
    "    ----------\n",
    "    - PAR: initial guess values for parameters to calibrate\n",
    "        PAR = [A, B, C, D, W_0, W_max, S_fc, S_w, rho_st, Kc]\n",
    "    - inputs: input quantities for calibration,\n",
    "        [d, d_sat, P, IRRobs, EPOT, WWobs, LAI, t_deg, obs]\n",
    "    - user_in: user-defined options\n",
    "        irri = user_in: if user_in=True, irrigation is estimated\n",
    "        and not taken as an input, else the input observed irrigation\n",
    "        is used in the soil water balance\n",
    "    \n",
    "    Return\n",
    "    -------\n",
    "    KGE from hydroeval between sigma0 observed and simulated.\n",
    "    \n",
    "    \"\"\"\n",
    "\n",
    "    # User input\n",
    "    irri = user_in\n",
    "    \n",
    "    # Unpack inputs\n",
    "    A, B, C, D, W_0, W_max, S_fc, S_w, rho_st, Kc = PAR\n",
    "    d, d_sat, P, IRRobs, EPOT, WWobs, veg, t_deg, obs = inputs\n",
    "    \n",
    "    W_fc = S_fc*W_max # water content at field capacity\n",
    "    W_w  = S_w*W_max # water content at wilting point\n",
    "    theta = t_deg*np.pi/180. # angle of incidence\n",
    "    \n",
    "    if irri==True: IRR = [0]*len(d) # daily, water content\n",
    "    else: IRR = IRRobs\n",
    "    \n",
    "    Ks = [0]*len(d) # daily, water stress coefficient\n",
    "    rho = [0]*len(d) # daily, depletion fraction\n",
    "    PS = [0]*len(d) # daily, deep percolation\n",
    "    W = [0]*len(d) # daily, water content\n",
    "    \n",
    "    W[0] = W_0*W_max\n",
    "    \n",
    "    for t in [i+1 for i in range(len(d)-1)]:\n",
    "        rho[t]=rho_st+0.04*(5-Kc*EPOT[t])\n",
    "        if W[t-1]>=(1-rho[t])*W_fc:\n",
    "            Ks[t]=1\n",
    "        elif (W[t-1]>W_w)and(W[t-1]<(1-rho[t])*W_fc):\n",
    "            Ks[t]=float(W[t-1]-W_w)/((1-rho[t])*(W_fc-W_w))\n",
    "        else: Ks[t]=0\n",
    "        \n",
    "        DOY=d[t].dayofyear\n",
    "        \n",
    "        # Irrigation estimate (for summer season only)\n",
    "        # Irrigation is estimated as the amount of water needed from the day\n",
    "        # before to take water content up to field capacity\n",
    "        if irri==True:\n",
    "            if np.logical_and(DOY>134,DOY<235): # summer season\n",
    "                if W[t-1]<=(1-rho[t])*W_fc: IRR[t]=W_fc-W[t-1]\n",
    "        \n",
    "        # Water balance\n",
    "        W[t]=W[t-1]+P[t]+IRR[t]-EPOT[t]*Kc*Ks[t]\n",
    "        \n",
    "        # Computation of deep percolation (water above field capacity)\n",
    "        if W[t]>W_fc:\n",
    "            PS[t]=W[t]-W_fc\n",
    "            W[t]=W_fc\n",
    "            \n",
    "    WW=np.array(W)/W_max   \n",
    "    WWsat = pd.DataFrame(timeseries(d,WW)).set_index(0).loc[d_sat][1].values\n",
    "    \n",
    "    T2 = np.exp((-2*B*veg)/np.cos(theta)) # two-way attenuation from the vegetation layer\n",
    "    sig0s = db_lin(C+D*WWsat) # define bare soil backscatter [fit in dB, then in lin]\n",
    "    sig0v = A*veg*np.cos(theta)*(1-T2) # define backscatter from the vegetation [fit in lin]\n",
    "    sig0_lin = T2*sig0s+sig0v\n",
    "    sig0=lin_db(sig0_lin) # from linear scale to dB\n",
    "        \n",
    "    OUT=he.evaluator(he.kge, sig0, obs) # OUT is kge, r, alpha, beta\n",
    "    KGE=OUT[0,:];\n",
    "\n",
    "    return [WW,IRR,sig0,KGE]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b00ed179-9c99-417f-aef7-28c43c33e793",
   "metadata": {},
   "source": [
    "# Global"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "5bac90cd-9a42-4de8-8a4b-7278fa5e4f84",
   "metadata": {},
   "outputs": [],
   "source": [
    "filename = f'irr_obs_'"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4c5a1587-bb69-4dc1-9ead-92e6edcd31e4",
   "metadata": {},
   "source": [
    "# Input data\n",
    "\n",
    "Input data formatting convention:\n",
    "- ausiliary variables for extraction of data (directory name, file name, etc...)\n",
    "- extraction into pd dataframe\n",
    "- cleaning, resampling: drop unnecessary columns, set index to daily DateIndex\n",
    "\n",
    "## Time resampling consistency\n",
    "\n",
    "- $\\sigma^0$ values are extracted with a timestamp aaaa-mm-dd hh:mm:ss with frequency 'H' (hourly), then are rounded by `.round()` to the midnight of the nearest day to have frequency 'D' (daily), e.g. a passage at 7 am on 1st july is rounded to 0 am of 1st july, a passage at 7 pm would be rounded at 0 am of 2nd july.\n",
    "- many quantities need to be resampled from hourly to daily datasets: use the `.resample()` method on a dataframe with hourly DatetimeIndex and pass the argument `origin='end_day'`. In this way, for each day X, data are considered between hours 1 and 24(=0 of day X+1) and the timestamp assigned is the one of the day X+1 (on which the operation ends). "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "650a493b-69cc-41bf-9134-12c129e96cca",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting...\n",
      "#-------------------------------------------------------------\n",
      "Use of satellite-derived SM is provided for comparison, not calibration.\n",
      "\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "Verbose data extraction? (Describe datasets/files) [y/n] y\n"
     ]
    }
   ],
   "source": [
    "print('Starting...\\n'+\n",
    "      '#-------------------------------------------------------------\\n'+\n",
    "      'Use of satellite-derived SM is provided for comparison, not calibration.\\n')\n",
    "verbose = True if input(\"Verbose data extraction? (Describe datasets/files) [y/n]\")=='y' else False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "9e94ec38-1f24-4f57-936d-fcaeb9a9e9a4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "DatetimeIndex: 1037 entries, 2015-01-01 to 2017-11-02\n",
      "Data columns (total 12 columns):\n",
      " #   Column              Non-Null Count  Dtype  \n",
      "---  ------              --------------  -----  \n",
      " 0   Irrigation_5        214 non-null    float64\n",
      " 1   Rainfall_5          1037 non-null   float64\n",
      " 2   ET_5                1037 non-null   float64\n",
      " 3   PET_5               1037 non-null   float64\n",
      " 4   SSM_ASCAT_5         1009 non-null   float64\n",
      " 5   SSM_CCI_combined_5  998 non-null    float64\n",
      " 6   SSM_CCI_active_5    972 non-null    float64\n",
      " 7   SSM_CCI_passive_5   925 non-null    float64\n",
      " 8   SSM_SMAP_5          609 non-null    float64\n",
      " 9   SSM_SMOS_5          598 non-null    float64\n",
      " 10  SSM_THEIA_5         179 non-null    float64\n",
      " 11  SSM_RT1_5           241 non-null    float64\n",
      "dtypes: float64(12)\n",
      "memory usage: 105.3 KB\n"
     ]
    }
   ],
   "source": [
    "#----------------------------------------------------------------------------\n",
    "# Field data from TEST_SITE\n",
    "# Daily data from 2015 to 2017, various gaps\n",
    "\n",
    "# Data extracted:\n",
    "# - rain (as input SWB)\n",
    "# - EPOT = potential evapotranspiration (as input SWB)\n",
    "\n",
    "namesite = 'ITALY_BUDRIO'\n",
    "siteID = '5'\n",
    "namefig = namesite+'_'+siteID\n",
    "\n",
    "site_df = xr.open_dataset(f'Inputs\\TEST_SITE\\TEST_SITE_{namesite}.nc',\n",
    "                         engine='netcdf4').to_dataframe();\n",
    "site_df = site_df.rename(columns={'Time_days':'Date'})\n",
    "site_df = site_df.set_index('Date')\n",
    "site_df = site_df.loc[:,[col for col in site_df.columns if col.endswith(siteID)]]\n",
    "if verbose: site_df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "b89b83e5-b2e3-4471-8992-670220106367",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "DatetimeIndex: 1150 entries, 2014-10-12 to 2022-11-28\n",
      "Data columns (total 8 columns):\n",
      " #   Column       Non-Null Count  Dtype         \n",
      "---  ------       --------------  -----         \n",
      " 0   Angle[°]     1150 non-null   float64       \n",
      " 1   Geometry     1150 non-null   object        \n",
      " 2   Orb          1150 non-null   int64         \n",
      " 3   Pass         1150 non-null   object        \n",
      " 4   VV_norm[dB]  1150 non-null   float64       \n",
      " 5   VH_norm[dB]  1150 non-null   float64       \n",
      " 6   CR           1150 non-null   float64       \n",
      " 7   Datetime     1150 non-null   datetime64[ns]\n",
      "dtypes: datetime64[ns](1), float64(4), int64(1), object(2)\n",
      "memory usage: 80.9+ KB\n"
     ]
    }
   ],
   "source": [
    "#----------------------------------------------------------------------------\n",
    "# Sigma0 values\n",
    "\n",
    "# Freq: D\n",
    "# Daily values of backscattering from 2014 to 2022 (complete S1 series)\n",
    "# Data extracted:\n",
    "# - sigma0 values, VV and VH\n",
    "# - angle of incidence of reference orbit (nearest to 40°)\n",
    "\n",
    "sigma_df = pd.read_csv('Data\\\\budrio-half.csv', delimiter='\\t');\n",
    "sigma_df['Datetime'] = sigma_df.Date.apply(lambda x : pd.to_datetime(x))\n",
    "sigma_df.Date = sigma_df.Date.apply(lambda x : pd.to_datetime(x).round(freq='D'))\n",
    "sigma_df = sigma_df.set_index('Date')\n",
    "if verbose: sigma_df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "id": "ed47b051-8a92-44ef-ab92-a67b1ba5c5ed",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "DatetimeIndex: 9474 entries, 2017-04-03 11:00:00 to 2020-09-01 20:00:00\n",
      "Data columns (total 4 columns):\n",
      " #   Column           Non-Null Count  Dtype  \n",
      "---  ------           --------------  -----  \n",
      " 0   SWC[m3/m3]       8888 non-null   float64\n",
      " 1   Pioggia[mm]      9394 non-null   float64\n",
      " 2   Irrigazione[mm]  9474 non-null   float64\n",
      " 3   Temperatura[°C]  9442 non-null   float64\n",
      "dtypes: float64(4)\n",
      "memory usage: 370.1 KB\n"
     ]
    }
   ],
   "source": [
    "#----------------------------------------------------------------------------\n",
    "# Budrio field data from platinum_df tables\n",
    "\n",
    "# Freq: H\n",
    "# Data extracted:\n",
    "# - SWC (as input SWB/comparison)\n",
    "# - rain (as input SWB)\n",
    "# - irrigation (as input SWB)\n",
    "# - temperature (as input SWB, ET0 estimate)\n",
    "\n",
    "platinum_df = pd.ExcelFile('Inputs\\Platinum_Budrio.xlsx', engine='openpyxl')\n",
    "platinum_df = pd.concat([platinum_df.parse('2017_1h'), platinum_df.parse('2020_1h')])\n",
    "\n",
    "# Column 'Date' contains date+hour = hourly information\n",
    "# Column 'Data' contains only date = daily information\n",
    "platinum_df['Ora_1'] = pd.to_datetime(platinum_df['Ora'].astype('str')).apply(lambda x: x.time())\n",
    "platinum_df['Data_1'] = pd.to_datetime(platinum_df['Data'].astype('str')).apply(lambda x: x.date())\n",
    "platinum_df['Datetime'] = platinum_df.apply(lambda r : dtt.datetime.combine(r['Data_1'],r['Ora_1']),1)\n",
    "platinum_df = platinum_df.drop(['ID', 'Data', 'Ora', 'Data_1', 'Ora_1', '214Pb[cps]'],axis=1)\n",
    "platinum_df = platinum_df.set_index('Datetime')\n",
    "platinum_resampled = platinum_df.resample('D', origin='end_day')\n",
    "if verbose: platinum_df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "8fd6579a-846a-4464-9557-38943d5c2cf0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "DatetimeIndex: 9475 entries, 2017-04-03 11:00:00 to 2020-09-01 20:00:00\n",
      "Data columns (total 12 columns):\n",
      " #   Column                          Non-Null Count  Dtype  \n",
      "---  ------                          --------------  -----  \n",
      " 0   Raffica di vento [m/s]          9474 non-null   float64\n",
      " 1   Radiazione solare [W/m2]        9474 non-null   float64\n",
      " 2   Direzione del vento [°]         9474 non-null   float64\n",
      " 3   Radiazione UV [MED]             9474 non-null   float64\n",
      " 4   Velocità del vento [m/s]        9474 non-null   float64\n",
      " 5   Pressione atmosferica [hPa]     9474 non-null   float64\n",
      " 6   Punto di rugiada [C°]           9474 non-null   float64\n",
      " 7   Temperatura Aria Netsens [C°]   5125 non-null   float64\n",
      " 8   Umidità aria Netsens [%]        5125 non-null   float64\n",
      " 9   Temperatura Aria Supporto [C°]  5125 non-null   float64\n",
      " 10  Temperatura Aria [C°]           4349 non-null   float64\n",
      " 11  Umidità aria [%]                4349 non-null   float64\n",
      "dtypes: float64(12)\n",
      "memory usage: 962.3 KB\n"
     ]
    }
   ],
   "source": [
    "#----------------------------------------------------------------------------\n",
    "# Budrio field data from meteo tables\n",
    "\n",
    "# Freq: H\n",
    "# Data extracted:\n",
    "# none\n",
    "# Needed for eto from FAO PM \n",
    "\n",
    "meteo_df = pd.ExcelFile('Inputs\\Budrio_Meteo.xlsx', engine='openpyxl')\n",
    "\n",
    "meteo_df = pd.concat([meteo_df.parse('2017'), meteo_df.parse('2020')]).set_index('ID')\n",
    "\n",
    "# Column 'Date' contains date+hour = hourly information\n",
    "meteo_df['Datetime'] = meteo_df.apply(lambda r : dtt.datetime.combine(r['Data'],r['Ora']),1)\n",
    "meteo_df = meteo_df.set_index('Datetime')\n",
    "meteo_df = meteo_df.drop(['Data', 'Ora'],axis=1)\n",
    "\n",
    "if verbose: meteo_df.info()\n",
    "# meteo_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "2affc40f-b8ea-4d76-8efa-d2ccb2ba3558",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "DatetimeIndex: 9474 entries, 2017-04-03 11:00:00 to 2020-09-01 20:00:00\n",
      "Data columns (total 16 columns):\n",
      " #   Column                          Non-Null Count  Dtype  \n",
      "---  ------                          --------------  -----  \n",
      " 0   Raffica di vento [m/s]          9473 non-null   float64\n",
      " 1   Radiazione solare [W/m2]        9473 non-null   float64\n",
      " 2   Direzione del vento [°]         9473 non-null   float64\n",
      " 3   Radiazione UV [MED]             9473 non-null   float64\n",
      " 4   Velocità del vento [m/s]        9473 non-null   float64\n",
      " 5   Pressione atmosferica [hPa]     9473 non-null   float64\n",
      " 6   Punto di rugiada [C°]           9473 non-null   float64\n",
      " 7   Temperatura Aria Netsens [C°]   5125 non-null   float64\n",
      " 8   Umidità aria Netsens [%]        5125 non-null   float64\n",
      " 9   Temperatura Aria Supporto [C°]  5125 non-null   float64\n",
      " 10  Temperatura Aria [C°]           4348 non-null   float64\n",
      " 11  Umidità aria [%]                4348 non-null   float64\n",
      " 12  SWC[m3/m3]                      8888 non-null   float64\n",
      " 13  Pioggia[mm]                     9394 non-null   float64\n",
      " 14  Irrigazione[mm]                 9474 non-null   float64\n",
      " 15  Temperatura[°C]                 9442 non-null   float64\n",
      "dtypes: float64(16)\n",
      "memory usage: 1.2 MB\n"
     ]
    }
   ],
   "source": [
    "# Budrio database\n",
    "# Freq: H\n",
    "# Merging of Platinum+Meteo\n",
    "\n",
    "meteo_h = pd.merge(right=platinum_df, left=meteo_df, on='Datetime')\n",
    "if verbose: meteo_h.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2db763eb-82db-40b8-bfa9-64b54fd081d5",
   "metadata": {},
   "source": [
    "After long and deep thinking\n",
    "and at least ten coffee drinking\n",
    "I have reached the conclusion\n",
    "that the best possible solution\n",
    "for the inputs' database \n",
    "is in fact the easiest case:\n",
    "take each column as it is,\n",
    "resample, sum or take the mean,\n",
    "give a name to every one\n",
    "and please take it easy for once!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1d933426-2b44-4844-9382-83f67a3cd906",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Build inputs as timeseries (using the nominal function)\n",
    "# timeseries(dates, data) -> matrix[columns={dates, data}]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "3a3ee129-16de-4ee9-b13f-ce36ef2c4dbb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ET0 calculation\n",
    "\n",
    "import datetime\n",
    "import sys\n",
    "\n",
    "sys.path.append('../')\n",
    "from modules.pyeto.pyeto import *\n",
    "\n",
    "def hargre(lat_deg, dates, temp_min, temp_max, temp_mean):\n",
    "    \"\"\"Hargreaves-Samani model for ET0 estimation from temperature input.\n",
    "    \n",
    "    Params\n",
    "    ------\n",
    "    - lat_deg: float\n",
    "    - dates: timestamp\n",
    "    - temp_*: float\n",
    "    \n",
    "    \n",
    "    \"\"\"\n",
    "    lat = deg2rad(lat_deg)  # Convert latitude in degrees to radians\n",
    "    day_of_year = dates.dayofyear\n",
    "    sol_decli = sol_dec(day_of_year) # Solar declination\n",
    "    sha = sunset_hour_angle(lat, sol_decli)\n",
    "    ird = inv_rel_dist_earth_sun(day_of_year)\n",
    "    et_radia = et_rad(lat, sol_decli, sha, ird) # Extraterrestrial radiation\n",
    "    return hargreaves(temp_min, temp_max, temp_mean, et_radia)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "id": "3c35f562-74d4-4a25-9549-e5192f44a9e3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "DatetimeIndex: 1248 entries, 2017-04-04 to 2020-09-02\n",
      "Data columns (total 1 columns):\n",
      " #   Column  Non-Null Count  Dtype  \n",
      "---  ------  --------------  -----  \n",
      " 0   ET0     396 non-null    float64\n",
      "dtypes: float64(1)\n",
      "memory usage: 19.5 KB\n"
     ]
    }
   ],
   "source": [
    "from IRRI_WCM.EPOT_Hargreaves_pyeto import *\n",
    "\n",
    "lat_deg = 44.570842547510622 # latitude of Budrio (deg)\n",
    "temp_min = platinum_resampled.min()['Temperatura[°C]'].values\n",
    "temp_max = platinum_resampled.max()['Temperatura[°C]'].values\n",
    "temp_mean = platinum_resampled.mean()['Temperatura[°C]'].values\n",
    "dates = platinum_resampled.asfreq().index\n",
    "eto = timeseries( dates,\n",
    "                 [ hargre(lat_deg, dates[i] , temp_min[i], temp_max[i], temp_mean[i])\n",
    "                  for i in range(len(dates)) ] )\n",
    "eto_df = pd.DataFrame(eto).rename(columns={0:'Date',1:'ET0'}).set_index('Date')\n",
    "if verbose: eto_df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ea6c299d-3b96-4f92-8418-c17bdc36d75f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "1290d52a-b9e5-41b0-8d6e-68649307e3ef",
   "metadata": {},
   "source": [
    "# [WIP]"
   ]
  },
  {
   "cell_type": "raw",
   "id": "88493635-a877-432a-b646-2c841e4b1386",
   "metadata": {},
   "source": [
    "# Hourly df with all data from platinum_df table and passage of satellite at correct hours\n",
    "df_h = pd.merge(right=platinum_df, left=sigma_df, on='Date', how='right'); df_h.info()\n",
    "\n",
    "print('\\n#----------------------------------------------------------------------------\\n')\n",
    "\n",
    "# Daily df with all data from platinum_df table and passage of satellite\n",
    "df = pd.merge(right=platinum_df, left=sigma_df, on='Date', how='inner'); df.info()"
   ]
  },
  {
   "cell_type": "raw",
   "id": "dca38bdf-1eec-4726-8609-1fc909787a7a",
   "metadata": {},
   "source": [
    "# Dates\n",
    "D_0 = site_df.index; set1 = {x for x in D_0}\n",
    "D_1 = platinum_df['Data']; set2 = {x for x in D_1}\n",
    "d = np.sort(np.array([*set1.intersection(set2)])) # dates, full\n",
    "\n",
    "d_sat = [pd.Timestamp(df.Data[i]) for i in range(len(df.index))]\n",
    "set1 = {x for x in d}; set2 = {x for x in d_sat}\n",
    "d_sat = np.sort(np.array([*set1.intersection(set2)])) # dates, passage of sat"
   ]
  },
  {
   "cell_type": "raw",
   "id": "1bbe2ae2-c2ae-43a7-be2c-af416f5a639c",
   "metadata": {},
   "source": [
    "# Backscattering\n",
    "# t_deg is the angle of orbit 95, to which all orbits are normalized\n",
    "# obs are the values of sigma0\n",
    "\n",
    "t_deg = [np.mean(df.loc[df.Orb==95]['Angle[°]'].values) for i in range(len(df.Orb.values))]\n",
    "obs = df.loc[d_sat]['VV_norm[dB]'].values\n",
    "obs_VH = df.loc[d_sat]['VH_norm[dB]'].values\n",
    "# rt1 = df.loc[d_sat]['RT1[-]']"
   ]
  },
  {
   "cell_type": "raw",
   "id": "40e73232-856c-4aeb-be38-20ef3ccd4ed3",
   "metadata": {},
   "source": [
    "# Vegetation indexes\n",
    "#############################################################################\n",
    "# redefine LAI dataset since I have changed the structure of df\n",
    "# take LAI directly and perform all operations of cleaning directly here\n",
    "# and merge datasets here\n",
    "\n",
    "LAI = df.loc[d_sat]['LAI[m2/m2]'].values\n",
    "cr = (db_lin(obs_VH)/db_lin(obs))\n",
    "\n",
    "df_NDVI = pd.read_csv(f'Data\\\\NDVI_GEE.csv', delimiter = \"\\t\")\n",
    "df_NDVI.Datetime = df_NDVI.Datetime.apply(lambda x:pd.Timestamp(x))\n",
    "NDVI = df_NDVI.set_index('Datetime').loc[d_sat]['NDVI'].values"
   ]
  },
  {
   "cell_type": "raw",
   "id": "f91e4fbf-778d-475c-b4f1-42d8b9dfcd1f",
   "metadata": {},
   "source": [
    "P = platinum_df.resample('1D',on='Date').sum().loc[d]['Pioggia[mm]'].values\n",
    "EPOT = site_df.loc[d][f'PET_{siteID}'].values # potential evapotranspiration (measured)\n",
    "IRRobs = platinum_df.resample('1D',on='Date').sum().loc[d]['Irrigazione[mm]'].values\n",
    "Wobs_gap = platinum_df.resample('1D',on='Date').mean().loc[d]['SWC[m3/m3]'].values\n",
    "Wobs = platinum_df.resample('1D',on='Date').mean().loc[d]['SWC[m3/m3]'].interpolate(method='linear').values\n",
    "WWobs_gap = (Wobs_gap-np.min(Wobs))/(np.max(Wobs)-np.min(Wobs))\n",
    "WWobs = norm(Wobs)\n",
    "\n",
    "index = input('Please provide name of vegetation index to use as input. [Options: LAI, cr, vh, NDVI]')\n",
    "if index=='LAI': veg=LAI; label_veg='LAI[-]'\n",
    "elif index=='NDVI': veg=NDVI; label_veg='NDVI[-]'\n",
    "elif index=='cr': veg=cr; label_veg=r'$\\sigma^0$ cross ratio VH/VV [-]'\n",
    "elif index=='vh': veg=db_lin(obs_VH); label_veg=r'$\\sigma^0$ [VH] [dB]'\n",
    "else: raise NameError('Please select one of the available options')"
   ]
  },
  {
   "cell_type": "raw",
   "id": "ff2f5499-d819-4290-8459-e79a0c788b2a",
   "metadata": {},
   "source": [
    "elif opt_time=='h':\n",
    "    df1 = pd.DataFrame(timeseries(site_df.Time_days, site_df[f'PET_{siteID}']))\\\n",
    "        .rename(columns={0:'Data', 1:'EPOT'})\n",
    "    epotdf=pd.merge(right=df1, left=platinum_df, on='Data', how='left')\n",
    "    EPOT = epotdf.EPOT.values\n",
    "    P = platinum_df['Pioggia[mm]'].values\n",
    "    IRRobs = platinum_df['Irrigazione[mm]'].values\n",
    "    Wobs_gap = platinum_df['SWC[m3/m3]'].values\n",
    "    Wobs = platinum_df['SWC[m3/m3]'].values\n",
    "    WWobs_gap = (Wobs_gap-np.min(Wobs))/(np.max(Wobs)-np.min(Wobs))\n",
    "    WWobs = norm(Wobs)"
   ]
  },
  {
   "cell_type": "raw",
   "id": "0880ea9b-318e-4d8e-8e8b-d253027c4d8f",
   "metadata": {},
   "source": [
    "# site_df, platinum_df, sigma_df\n",
    "platinum_df_reduced=platinum_df.resample('1D').mean()\n",
    "#platinum_df_reduced=platinum_df_reduced.drop(['Pioggia[mm]','Irrigazione[mm]','Temperatura[°C]'])\n",
    "\n",
    "daily_field = pd.merge(\n",
    "    right=site_df,\n",
    "    left=platinum_df_reduced,\n",
    "    on='Date',\n",
    "    how='inner',\n",
    "); daily_field"
   ]
  },
  {
   "cell_type": "raw",
   "id": "2aae6836-9459-4d53-9bfe-c8469ca7a520",
   "metadata": {},
   "source": [
    "daily = pd.merge(\n",
    "    right=daily_field,\n",
    "    left=sigma_df,\n",
    "    right_on='Date',\n",
    "    left_on='Date',\n",
    "    how='right'\n",
    ")\n",
    "#daily=daily.set_index('Date')\n",
    "daily.info()"
   ]
  },
  {
   "cell_type": "raw",
   "id": "a3450931-2c02-4e73-8f58-2ef12d13c872",
   "metadata": {},
   "source": [
    "daily = pd.merge_asof(\n",
    "    right=daily_field,\n",
    "    left=sigma_df,\n",
    "    #right_on='Data', left_on='Date',\n",
    "    # on='Date',\n",
    "    left_index=True,\n",
    "    right_index=True,\n",
    "    direction='nearest',\n",
    "    tolerance=pd.Timedelta(\"4d\"),\n",
    ")\n",
    "#daily=daily.set_index('Date')\n",
    "daily.info()"
   ]
  },
  {
   "cell_type": "raw",
   "id": "fffc3864-4567-4e8a-9f5c-9fdc05f69d8f",
   "metadata": {},
   "source": [
    "daily"
   ]
  },
  {
   "cell_type": "raw",
   "id": "5a96a7ac-aeea-4e97-8d31-e04c376c1e6b",
   "metadata": {},
   "source": [
    "daily.iloc[250:300,:]"
   ]
  },
  {
   "cell_type": "raw",
   "id": "13011db6-3553-4844-bbb7-6acc5d6154b8",
   "metadata": {},
   "source": [
    "daily.loc[d]"
   ]
  },
  {
   "cell_type": "raw",
   "id": "4c8959ee-79f7-4edf-b075-f19d8594eebe",
   "metadata": {},
   "source": [
    "pd.DatetimeIndex(daily.index.date)"
   ]
  },
  {
   "cell_type": "raw",
   "id": "766e1373-8f9e-4ab8-8c1e-dc92cf102f84",
   "metadata": {},
   "source": [
    "d_index = pd.DatetimeIndex(d); d_index"
   ]
  },
  {
   "cell_type": "raw",
   "id": "98c0cc4b-32b6-428a-9493-55bb27893fe1",
   "metadata": {},
   "source": [
    "d_index[0]"
   ]
  },
  {
   "cell_type": "raw",
   "id": "b1f8ebfb-96de-4287-8862-571d7e7010fa",
   "metadata": {},
   "source": [
    "daily.loc[d_index[0],:]"
   ]
  },
  {
   "cell_type": "raw",
   "id": "86d9e1fc-e6d2-4b4e-96a2-abce52b33e06",
   "metadata": {},
   "source": [
    "pd.DatetimeIndex(daily.index.values)"
   ]
  },
  {
   "cell_type": "raw",
   "id": "56470c92-68f5-4d34-a670-63240339d3f1",
   "metadata": {},
   "source": [
    "sigma_df.index"
   ]
  },
  {
   "cell_type": "raw",
   "id": "988b39cc-b18c-4a56-ab0c-40d7a093def1",
   "metadata": {},
   "source": [
    "daily.loc[d[0]]"
   ]
  },
  {
   "cell_type": "raw",
   "id": "8115322a-310b-4145-88c1-c4352428eca8",
   "metadata": {},
   "source": [
    "d_sat[0]"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "satellite",
   "language": "python",
   "name": "satellite"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
