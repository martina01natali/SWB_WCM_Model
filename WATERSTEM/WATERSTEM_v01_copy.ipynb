{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "ca095557-389b-45c4-b242-5f5c7d8e0350",
   "metadata": {},
   "source": [
    "# WATERSTEM - IRRmodel\\*WCM calibration with PSO on KGE of $\\sigma^0$\n",
    "\n",
    "Hello, and welcome back.\n",
    "\n",
    "\n",
    "The DEF code is a final, cleaned and commented version.\n",
    "This version implements an hourly ET0 calculated with hourly FAO-56 Penman-Monteith and a SWB model that is properly corrected for hourly calculation of the evapotranspiration.\n",
    "Kc curves are also externally defined in a module of their own."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d2af933c-6ff1-4900-b16d-2ecc9c0b8f20",
   "metadata": {},
   "source": [
    "# ToDo\n",
    "\n",
    "- [ ] retrieve unique s0 over the fields (multiple data are duplicated): based on experience, this may be due on errors in the merging of dataframes while using 'nearest' merging methods; UPDATE: same day, different hour -> options: average data / select ascending/descending orbits [choice: average data]; UPDATE: also some same day, same hour\n",
    "- [ ] retrieve and flag in metadata the true angle of normalization of s0 data [right now fix @ 41°]\n",
    "- [x] get bounds of soil franco-argilloso from FAO56"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 268,
   "id": "da87de2c-53e1-4b80-88cb-7a2327190f1f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.append('../')\n",
    "\n",
    "from modules.funcs import *\n",
    "from modules.funcs_io import *\n",
    "from modules.funcs_pso import *\n",
    "from modules.funcs_plot import *\n",
    "from modules.funcs_analysis import *\n",
    "from modules.IRRI_WCM_model import *\n",
    "from modules.EPOT_Hargreaves_pyeto import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 269,
   "id": "84134f3f-db26-4a4b-9017-1e6431056e28",
   "metadata": {},
   "outputs": [],
   "source": [
    "print('Starting...\\n'\n",
    "      +'#-------------------------------------------------------------\\n'\n",
    "     )\n",
    "verbose = True # if input(\"Verbose data extraction? (Describe datasets/files) [y/n]\")=='y' else False\n",
    "\n",
    "# print('\\n#-------------WCM model parameters-------------')\n",
    "units = 'lin' # input('Calibrate WCM in linear or dB scale (determines scale of A)? [lin/db]')\n",
    "opt_veg = 'NDVI'\n",
    "\n",
    "# print('\\n#------------Optimization parameters-----------')\n",
    "opt_calib = '1' # input('Cost function (KGE) on sigma0 (1) or sigma0 and soil moisture (2)? [1/2]')\n",
    "opt_cost = 'KGE'\n",
    "\n",
    "print('\\n#------------Field parameters-----------')\n",
    "opt_field = input('San Lorenzo 1 or 2? [1/2]')\n",
    "opt_year = input('Choose a year for calibration (1/1 to 31/12) or \"whole\" period')\n",
    "if not opt_year=='whole': opt_year=int(opt_year)\n",
    "opt_static =  input('Do you want to fix static parameters A,B,D? [y/n]')\n",
    "if opt_static=='y':\n",
    "    opt_root =    input('Provide root folder for static parameters log.')\n",
    "    opt_pattern = input('Provide pattern to match for parameters log (can use wildcards).')\n",
    "    PAR_dict_static = read_json(search_fname(opt_root, opt_pattern))\n",
    "\n",
    "print('\\n#------------Calibration parameters-----------')\n",
    "PAR_str_add = '_' + input('Any addition to parameters\\' names? [Type string to add]')\n",
    "nrun = int(input('Number of runs? (10 is min to study distribution of parameters.) '))\n",
    "n_particles = int(input('Number of particles: '))\n",
    "n_step = int(input('Number of optimization steps: '))\n",
    "optim = input('Global or Local PSO optimizer? [[global]/local] ')\n",
    "if optim=='local': norma = 1 if input('Which norm? [l1/l2] ')=='l1' else 2\n",
    "verbose_calib = True if input('Verbose during calibration? [y/n]')=='y' else False\n",
    "automate = True if input('Run and save everything automatically? [y/n]')=='y' else False\n",
    "\n",
    "# check if params are already present\n",
    "# opt_params = input('Params already present: overwrite [y] or append [n]? [y/n]') if len(params) else ''\n",
    "# if opt_params=='y': params = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 270,
   "id": "5bef1c04-b4dd-47ec-a497-9b494a3f636f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plotter for all columns of data\n",
    "\n",
    "def plot_columns(df):\n",
    "    fig, ax = plt.subplots(figsize=(14,6))\n",
    "    \n",
    "    for column in df.columns:\n",
    "        if df[column].dtype == 'object':\n",
    "            continue  # Skip non-numeric columns\n",
    "        \n",
    "        ax.plot(df.index, df[column], label=column)\n",
    "    \n",
    "    ax.legend()\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 271,
   "id": "f4857204-21b0-4ba3-9c43-a5003bc17514",
   "metadata": {},
   "outputs": [],
   "source": [
    "#############################################################################\n",
    "# METACODING\n",
    "#############################################################################\n",
    "\n",
    "def check_non_unique_index(df):\n",
    "    non_unique_index = df.index.duplicated(keep=False)\n",
    "    if non_unique_index.any():\n",
    "        non_unique_labels = df.index[non_unique_index]\n",
    "        print(\"Non-unique index labels:\")\n",
    "        print(non_unique_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 272,
   "id": "7bb6f530-eeb9-452d-8522-5a6444abecf7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# File paths\n",
    "# ----------\n",
    "# Meteo data\n",
    "file_meteo             = './Pascoli_UNIFI_dati_meteo/Daily_precipitation_SanLorenzo.csv'\n",
    "file_temp              = './Pascoli_UNIFI_dati_meteo/Daily_temperatures_SanLorenzo.csv'\n",
    "file_pet_sanlorenzo1   = './Pascoli_UNIFI_PET/PET_SanLorenzo1.csv'\n",
    "file_pet_sanlorenzo2   = './Pascoli_UNIFI_PET/PET_SanLorenzo2.csv'\n",
    "file_ndvi_sanlorenzo1  = './Pascoli_UNIFI_NDVI/NDVI_SanLorenzo1.csv'\n",
    "file_ndvi_sanlorenzo2  = './Pascoli_UNIFI_NDVI/NDVI_SanLorenzo2.csv'\n",
    "\n",
    "\n",
    "# s0 data\n",
    "file_s0_sanlorenzo1 = './Pascoli_UNIFI_mean-sigma0/sanlorenzo1.csv'\n",
    "file_s0_sanlorenzo2 = './Pascoli_UNIFI_mean-sigma0/sanlorenzo2.csv'\n",
    "\n",
    "\n",
    "\n",
    "# Dataframes\n",
    "# ----------\n",
    "# Meteo data\n",
    "df_meteo            = pd.read_csv(file_meteo);\n",
    "df_temp             = pd.read_csv(file_temp);\n",
    "df_pet_sanlorenzo1  = pd.read_csv(file_pet_sanlorenzo1)\n",
    "df_pet_sanlorenzo2  = pd.read_csv(file_pet_sanlorenzo2)\n",
    "df_ndvi_sanlorenzo1 = pd.read_csv(file_ndvi_sanlorenzo1, delimiter=';');\n",
    "df_ndvi_sanlorenzo2 = pd.read_csv(file_ndvi_sanlorenzo2, delimiter=';');\n",
    "\n",
    "# s0 data\n",
    "df_s0_sanlorenzo1   = pd.read_csv(file_s0_sanlorenzo1, delimiter='\\t');\n",
    "df_s0_sanlorenzo2   = pd.read_csv(file_s0_sanlorenzo2, delimiter='\\t');"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 273,
   "id": "24546449-b1e7-4c72-bfd6-378ab5ea2e3a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set daily, DateTimeIndex for all dataframes\n",
    "df_meteo['Date'] = [pd.to_datetime(x.date()) for x in pd.to_datetime(df_meteo['Date'], format='%d/%m/%Y')];\n",
    "df_meteo.set_index('Date', inplace=True);\n",
    "\n",
    "# meteo dataframe - cleaning\n",
    "for df in [\n",
    "    df_temp,\n",
    "    df_pet_sanlorenzo1,\n",
    "    df_pet_sanlorenzo2,\n",
    "    df_ndvi_sanlorenzo1,\n",
    "    df_ndvi_sanlorenzo2,\n",
    "    df_s0_sanlorenzo1,\n",
    "    df_s0_sanlorenzo2,\n",
    "]:\n",
    "    df['Date'] = [pd.to_datetime(x.date()) for x in pd.to_datetime(df['Date'],  format='mixed')]\n",
    "    # df['Date'] = [pd.to_datetime(x.date()) for x in pd.to_datetime(df['Date'],  infer_datetime_format=True)]\n",
    "    df.set_index('Date', inplace=True);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 274,
   "id": "e58c17a1-01e2-476d-9825-55a9c9206f7f",
   "metadata": {},
   "outputs": [],
   "source": [
    "check_non_unique_index(df_s0_sanlorenzo1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 275,
   "id": "8fb1dae6-04f6-4c2f-a948-38b8fb6afdcd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# s0 dataframe - cleaning\n",
    "df_s0_sanlorenzo1['data'] = df_s0_sanlorenzo1.index\n",
    "df_s0_sanlorenzo2['data'] = df_s0_sanlorenzo2.index\n",
    "df_s0_sanlorenzo1 = df_s0_sanlorenzo1.groupby('data').mean(numeric_only=True)\n",
    "df_s0_sanlorenzo2 = df_s0_sanlorenzo2.groupby('data').mean(numeric_only=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 276,
   "id": "eaa73867-1dfd-4ee8-a957-05182957bf17",
   "metadata": {},
   "outputs": [],
   "source": [
    "check_non_unique_index(df_s0_sanlorenzo1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 277,
   "id": "4ccb69f9-813f-46c9-bdd0-2b077f303af9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Clean useless columns\n",
    "\n",
    "# Meteo data\n",
    "df_meteo.drop(df_meteo.columns.difference(['Prec_mm']), axis=1, inplace=True)\n",
    "# df_temp.drop()\n",
    "\n",
    "# PET data (from MODIS16A) are the sum over a 8 days period, so need to be divided by 8\n",
    "# No conversion factor is needed for units of measurements since kg/m^2/day = mm/day\n",
    "df_pet_sanlorenzo1['PET_mean[mm/day]'] = df_pet_sanlorenzo1['PET_mean (kg/m2/8day)']/8\n",
    "df_pet_sanlorenzo2['PET_mean[mm/day]'] = df_pet_sanlorenzo2['PET_mean (kg/m2/8day)']/8\n",
    "df_pet_sanlorenzo1.drop(df_pet_sanlorenzo1.columns.difference(['PET_mean[mm/day]']), axis=1, inplace=True)\n",
    "df_pet_sanlorenzo2.drop(df_pet_sanlorenzo2.columns.difference(['PET_mean[mm/day]']), axis=1, inplace=True)\n",
    "df_pet_sanlorenzo1 = df_pet_sanlorenzo1.resample('D').asfreq().interpolate(method='linear')\n",
    "df_pet_sanlorenzo2 = df_pet_sanlorenzo2.resample('D').asfreq().interpolate(method='linear')\n",
    "    \n",
    "df_ndvi_sanlorenzo1.drop(df_ndvi_sanlorenzo1.columns.difference(['NDVI_mean']), axis=1, inplace=True)\n",
    "df_ndvi_sanlorenzo2.drop(df_ndvi_sanlorenzo2.columns.difference(['NDVI_mean']), axis=1, inplace=True)\n",
    "df_ndvi_sanlorenzo1 = df_ndvi_sanlorenzo1.resample('D').asfreq().interpolate(method='linear')\n",
    "df_ndvi_sanlorenzo2 = df_ndvi_sanlorenzo2.resample('D').asfreq().interpolate(method='linear')\n",
    "\n",
    "# s0 data\n",
    "df_s0_sanlorenzo1.drop(df_s0_sanlorenzo1.columns.difference(['VV_norm[dB]']), axis=1, inplace=True)  \n",
    "df_s0_sanlorenzo2.drop(df_s0_sanlorenzo2.columns.difference(['VV_norm[dB]']), axis=1, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 278,
   "id": "f76c7f8c-94d8-483f-87fa-f58a415da6fa",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Merge dataframes for both sanlorenzo1 and sanlorenzo2 (suffixes _1, _2)\n",
    "# Daily data to use as input in SWB\n",
    "df0 = pd.merge(df_ndvi_sanlorenzo1, df_ndvi_sanlorenzo2, left_index=True, right_index=True, suffixes=['_1', '_2']);\n",
    "df1 = pd.merge_asof(df_meteo, df_temp, left_index=True, right_index=True)\n",
    "df2 = pd.merge(df1, df_pet_sanlorenzo1, left_index=True, right_index=True)\n",
    "df3 = pd.merge_asof(df2, df_pet_sanlorenzo2, left_index=True, right_index=True, suffixes=['_1', '_2'])\n",
    "df4 = pd.merge(df3, df0, left_index=True, right_index=True).dropna(); df4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 279,
   "id": "ef0f9be7",
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": [
    "import json\n",
    "\n",
    "root_shapefile = '../Inputs/Shapefiles/Pascoli_UNIFI/'\n",
    "fname_shapefile = 'SanLorenzo'+opt_field+'.json'\n",
    "\n",
    "with open(root_shapefile+fname_shapefile) as file: shapefile = json.load(file)\n",
    "coordinates = shapefile['features'][0]['geometry']['coordinates'];\n",
    "lons = np.array([x[0] for x in coordinates[0]])\n",
    "lats = np.array([x[1] for x in coordinates[0]])\n",
    "mean_lats = (lats.min()+lats.max())/2; mean_lats\n",
    "lat_deg = mean_lats # latitude (deg)\n",
    "\n",
    "df = df4\n",
    "temp_tag = ['T_MIN','T_MAX']\n",
    "temp_min = df[temp_tag[0]].values\n",
    "temp_max = df[temp_tag[1]].values\n",
    "temp_mean = (temp_min+temp_max*2)/3\n",
    "dates = df.index; dates.values\n",
    "eto = timeseries( dates,\n",
    "                 [\n",
    "                     hargre(lat_deg, dates[i] , temp_min[i], temp_max[i], temp_mean[i])\n",
    "                  for i in range(len(dates))\n",
    "                 ] )\n",
    "eto_df = pd.DataFrame(eto).rename(columns={0:'Date',1:'PET_Hargre[mm/day]'}).set_index('Date')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 280,
   "outputs": [],
   "source": [
    "input_swb = pd.merge(df4, eto_df, left_index=True, right_index=True); input_swb"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 281,
   "outputs": [],
   "source": [
    "# Check consistency of PET data from Hargreaves formula with MODIS derived\n",
    "Rvalue(input_swb['PET_mean[mm/day]_1'], input_swb['PET_Hargre[mm/day]'])\n",
    "bias(input_swb['PET_mean[mm/day]_1'], input_swb['PET_Hargre[mm/day]'])\n",
    "np.mean(input_swb['PET_Hargre[mm/day]'])\n",
    "np.mean(input_swb['PET_mean[mm/day]_1'])"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 282,
   "outputs": [],
   "source": [
    "plot_columns(input_swb)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 283,
   "outputs": [],
   "source": [
    "# Merge dataframes for both sanlorenzo1 and sanlorenzo2 (suffixes _1, _2)\n",
    "# Multi-daily data to use as input in WCM\n",
    "df1 = pd.merge(df_ndvi_sanlorenzo1, df_ndvi_sanlorenzo2, left_index=True, right_index=True, suffixes=['_1', '_2']);\n",
    "df2 = pd.merge(df1, df_s0_sanlorenzo1, left_index=True, right_index=True);\n",
    "\n",
    "input_wcm = pd.merge(df2, df_s0_sanlorenzo2, left_index=True, right_index=True, suffixes=['_1', '_2']); input_wcm"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 284,
   "outputs": [],
   "source": [
    "# List of dates\n",
    "if opt_year=='whole': t = [x for x in input_swb.index]\n",
    "else: t = [x for x in input_swb.index if x.year==opt_year]\n",
    "\n",
    "# Hours of passage of satellite, intersect with complete days\n",
    "set1 = {x for x in input_swb.index}; set2 = {x for x in input_wcm.index};\n",
    "intersect = np.sort(np.array([*set1.intersection(set2)]))\n",
    "\n",
    "if opt_year=='whole': t_sat = [x for x in intersect]\n",
    "else: t_sat = [x for x in intersect if x.year==opt_year]\n",
    "\n",
    "\n",
    "P       = input_swb.loc[t]['Prec_mm'].values # [mm]\n",
    "EPOT    = input_swb.loc[t]['PET_Hargre[mm/day]'].values # [mm/day]\n",
    "# EPOT    = input_swb.loc[t][f'PET_mean[mm/day]_{opt_field}'].values # [mm/day]\n",
    "rho_st  = 0.6 # standard depletion fraction [grazing pasture, Table 22]\n",
    "\n",
    "# Crop coefficient curve is assumed equal to NDVI curve (daily)\n",
    "# According to FAO56 Kc values for pasture are in [0.3, 0.8]\n",
    "# which is compatible with the range of NDVI values\n",
    "# Kc = Kc_curve(year, t)\n",
    "Kc      = input_swb.loc[t][f'NDVI_mean_{opt_field}'].values # [-]\n",
    "veg     = input_wcm.loc[t_sat][f'NDVI_mean_{opt_field}'].values # [-]\n",
    "\n",
    "angle   = np.array([41]*len(t_sat)) # input_wcm.loc[t_sat]['Angle'].values # [°]\n",
    "s0      = input_wcm.loc[t_sat][f'VV_norm[dB]_{opt_field}'].values # [dB]\n",
    "freq    = 1.4 # 6, 4, 1.4     # [GHz] frequency for DoI computation\n",
    "\n",
    "# Soil texture list\n",
    "# 28,7% sabbia, 36,0% limo, 35,3% argilla\n",
    "soil = [28.7, 35,3] # [sand, clay]\n",
    "WW_fc = np.mean([0.24, 0.40])\n",
    "WW_w = np.mean([0.07, 0.24])\n",
    "\n",
    "# List of inputs for calibrating the model\n",
    "inputs  = [t, t_sat, P, EPOT, Kc, veg, angle, s0, freq, rho_st, soil, WW_fc, WW_w]"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "id": "43f9244b-b926-457a-87fc-cdf8a730afb0",
   "metadata": {},
   "source": [
    "# SWB+WCM model, daily"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 285,
   "outputs": [],
   "source": [
    "#############################################################################\n",
    "# Soil Water Balance + Water Cloud model daily\n",
    "# No irrigation\n",
    "#############################################################################\n",
    "\n",
    "def SWB_WCM_WATERSTEM(PAR, inputs, user_in):\n",
    "    \"\"\"Soil Water Balance and Water Cloud Model integration\n",
    "\n",
    "    The soil water balance model (SWB) produces an estimate of the soil water\n",
    "    content WW [%] that is used to simulate $\\sigma^0$ by a water cloud\n",
    "    model (WCM).\n",
    "\n",
    "    Inputs\n",
    "    ----------\n",
    "    - PAR: initial guess values for parameters to calibrate\n",
    "    - inputs: input quantities for calibration\n",
    "\n",
    "    Return\n",
    "    -------\n",
    "    KGE from hydroeval between sigma0 observed and simulated.\n",
    "\n",
    "    \"\"\"\n",
    "\n",
    "    # User_in options\n",
    "    # opt_static = user_in # deprecated, here for compatibility\n",
    "\n",
    "    # Inputs\n",
    "    A, B, C, D, Kc0 = PAR\n",
    "    t, t_sat, P, EPOT, Kc, veg, angle, s0, freq, rho_st, soil, WW_fc, WW_w = inputs\n",
    "\n",
    "    angle_m = np.mean(angle)\n",
    "    Ks      = 0. # water stress coefficient\n",
    "    rho     = 0. # depletion fraction\n",
    "    WW      = np.array([0.2]*len(t), dtype=float) # water content [m3/m3]\n",
    "    WW[0]   = .2 # initial value of sm [m3/m3]\n",
    "    depth   = 0. # dynamic depth [mm]\n",
    "\n",
    "    COST   = .0   # additional cost to KGE\n",
    "    LAMBDA = 1000 # Lagrange multiplier\n",
    "\n",
    "    for i in [i+1 for i in range(len(t)-1)]:\n",
    "\n",
    "        # Compute DoI of W[i-1]\n",
    "        depth = (doi(freq=freq,\n",
    "                     sand=soil[0], clay=soil[1],\n",
    "                     water=WW[i-1],\n",
    "                     angle=angle_m)\\\n",
    "                    *1000) # *1000 accounts for going from [m] to [mm]\n",
    "\n",
    "        # Build Ks curve\n",
    "        # Compute crop coeff and depletion fraction\n",
    "        rho = rho_st+0.04*(5-Kc[i]*Kc0*EPOT[i]) # [mm/day]\n",
    "        if   rho<0.1: COST += (rho-0.1)**2      # regularization\n",
    "        elif rho>0.8: COST += (rho-0.8)**2      # regularization\n",
    "\n",
    "        if WW[i-1]>=((1-rho)*WW_fc+rho*WW_w):\n",
    "            Ks=1\n",
    "        elif (WW[i-1]<((1-rho)*WW_fc+rho*WW_w))and(WW[i-1]>WW_w):\n",
    "            Ks=((WW[i-1]-WW_w)/((1-rho)*(WW_fc-WW_w)))\n",
    "        else: Ks=0.\n",
    "\n",
    "        # Water balance [mm]\n",
    "        WW[i]=WW[i-1]+(P[i]-EPOT[i]*Kc[i]*Kc0*Ks)/depth\n",
    "\n",
    "        # Computation of deep percolation (water above field capacity)\n",
    "        if WW[i]>WW_fc: WW[i]=WW_fc\n",
    "\n",
    "        # Regularization for non-physical data below wilting point\n",
    "        # if WW[i]<WW_w: COST += (WW[i]-WW_w)**2\n",
    "\n",
    "    WWsat = np.array([ x[1] for x in timeseries(t,WW) if x[0] in t_sat ])\n",
    "\n",
    "    # Water Cloud Model\n",
    "    s0_sim,KGE = WCM([A,B,C,D], [WWsat,veg,angle,s0])\n",
    "\n",
    "    KGE += -LAMBDA*COST\n",
    "\n",
    "    return [WW,s0_sim,KGE]\n"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 286,
   "outputs": [],
   "source": [
    "def calc_depth(freq:float, soil:list, water:list, angle:float)->list:\n",
    "    depth = [doi(freq=freq, sand=soil[0], clay=soil[1], water=w, angle=angle)*1000 for w in water]\n",
    "    return depth\n",
    "\n",
    "\n",
    "def calc_rho(rho_st:float, Kc:list, Kc0:float, EPOT:list)->list:\n",
    "    rho = [rho_st+0.04*(5-Kc[i]*Kc0*EPOT[i]) for i in range(len(Kc))]\n",
    "    return rho\n",
    "\n",
    "\n",
    "def calc_Ks(WW:list, rho:list, WW_fc, WW_w)->list:\n",
    "    t = len(WW)\n",
    "    Ks = []\n",
    "    for i in range(t):\n",
    "        if WW[i-1]>=((1-rho)*WW_fc+rho*WW_w):\n",
    "            Ks.append(1)\n",
    "        elif (WW[i-1]<((1-rho)*WW_fc+rho*WW_w))and(WW[i-1]>WW_w):\n",
    "            Ks.append((WW[i-1]-WW_w)/((1-rho)*(WW_fc-WW_w)))\n",
    "        else: Ks.append(0)\n",
    "    return Ks"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 287,
   "id": "f5730194-e49a-4a55-933e-bf900ea510d5",
   "metadata": {},
   "outputs": [],
   "source": [
    "def pso_calib_irri(PAR):\n",
    "    \"\"\"Ausiliary function for PSO optimization\"\"\"\n",
    "    global inputs\n",
    "    n_particles = PAR.shape[0]\n",
    "    err = np.zeros(n_particles)\n",
    "    for i in range(n_particles):\n",
    "        WW,s0_sim,KGE = SWB_WCM_WATERSTEM(PAR[i], inputs, user_in)\n",
    "        err[i] = 1 - KGE\n",
    "    return err"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ecca693d-78de-4f2d-be7b-106646d0cc8d",
   "metadata": {
    "tags": []
   },
   "source": [
    "# Calibration SWB+WCM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 288,
   "id": "331ebeca-623e-4ab5-adba-07a1ad8591ad",
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": [
    "# Calibration SWB+WCM\n",
    "# ----------------------------------------------------------------------------\n",
    "\n",
    "# Guess parameters for WCM\n",
    "A      = 0.3; B      = 1.5; C      = -15; D      = 30   # guess values for WCM parameters\n",
    "Kc0    = 1    # [-] scaling factor for crop specific coefficient\n",
    "\n",
    "# PAR default\n",
    "PAR_str = [r'$A$', r'$B$', r'$C$', r'$D$', r'$W_{fc}$', r'$W_w$', r'$\\rho_{st}$', r'$K_{c0}$']\n",
    "PAR_str_stat = [r'$A$', r'$B$', r'$D$'] # static parameters, don't change in time, site-dependent\n",
    "\n",
    "# PAR to calibrate\n",
    "# A, B, C, D, d_0, WW_fc, WW_w, rho_st, Kc0\n",
    "PAR     = [A, B, C, D, Kc0]\n",
    "PARn_str= [r'$A$', r'$B$', r'$C$', r'$D$', r'$K_{c0}$']\n",
    "\n",
    "bounds = (\n",
    "    np.array([0, 0, -30,  10, 0], dtype=float), # low\n",
    "    np.array([5, 3,  -5, 100, 2], dtype=float), # up\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 289,
   "outputs": [],
   "source": [
    "# PAR static\n",
    "user_in = opt_static\n",
    "\n",
    "if opt_static=='y':\n",
    "\n",
    "    PS = [] # PAR_static\n",
    "    E = [] # devs of PAR static\n",
    "    # Static parameters are appended to inputs\n",
    "    for key in PAR_dict_static.keys():\n",
    "        d = PAR_dict_static[key]\n",
    "        if d[1]=='cal':\n",
    "            PS.append(d[3])\n",
    "            E.append(d[4])\n",
    "\n",
    "    A, B, C, D, Kc0 = PS\n",
    "    PAR     = PS\n",
    "    bounds = (\n",
    "        np.array([PS[0]-E[0], PS[1]-E[1], -30, PS[3]-E[3], 0], dtype=float), # low\n",
    "        np.array([PS[0]+E[0], PS[1]+E[1],  -5, PS[3]+E[3], 2], dtype=float), # up\n",
    "        )"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 290,
   "id": "efe3ca46-2e95-4ade-9091-13f3190d7b73",
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": [
    "print('Starting calibration...\\n'+\n",
    "      '#-------------------------------------------------------------\\n')\n",
    "\n",
    "from pyswarms.backend.handlers import OptionsHandler\n",
    "\n",
    "# if opt_params=='y':\n",
    "params = []\n",
    "start = time.time()\n",
    "for i in range(int(nrun)):\n",
    "    print('Run number ', i+1)\n",
    "\n",
    "    optim='global'\n",
    "    options = {'c1': 2.05, 'c2': 2.05, 'w': 0.6}\n",
    "    oh_strategy = {\"w\":'lin_variation', 'c1':'lin_variation', 'c2':'lin_variation'}\n",
    "    bh_strategy = 'shrink'\n",
    "    vh_strategy = 'invert'\n",
    "    init_pos = np.array([PAR]*int(n_particles))\n",
    "    optimizer = ps.single.GlobalBestPSO(n_particles=int(n_particles),\n",
    "                                        dimensions=len(PAR),\n",
    "                                        options=options,\n",
    "                                        bounds=bounds,\n",
    "                                        oh_strategy=oh_strategy,\n",
    "                                        bh_strategy=bh_strategy,\n",
    "                                        vh_strategy=vh_strategy,\n",
    "                                        init_pos=init_pos,\n",
    "                                       )\n",
    "    cost, PARn = optimizer.optimize(pso_calib_irri, n_step, verbose=verbose_calib)\n",
    "    params.append(PARn)\n",
    "    end = time.time()\n",
    "\n",
    "    if i==0:\n",
    "        time_sec = round(end-start, 2)\n",
    "        time_min =  round((end-start)/60, 2)\n",
    "        print(time_min, ' min for last run,', time_min*nrun , ' min estimated')\n",
    "    print('Time left: ', round((start+time_sec*nrun-end)/60,2), 'min')\n",
    "\n",
    "timestr = time.strftime(\"%y%m%d-%H%M%S\"); print('Timestring: ', timestr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 291,
   "id": "a476b36c-d882-4397-a23a-9aca7bf554c0",
   "metadata": {},
   "outputs": [],
   "source": [
    "print('Timing: ', round((end-start)/60/nrun, 2), ' min for 1 run,', round((end-start)/60, 2), 'min total')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 292,
   "outputs": [],
   "source": [
    "print('\\n#--------------------------------------------------\\n',f'Filename=sanlorenzo{opt_field}_{opt_year}_{timestr}_*')\n",
    "timestr=f'sanlorenzo{opt_field}_{opt_year}_{timestr}'"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 293,
   "outputs": [],
   "source": [
    "root = 'Plot/'"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "id": "ff7b8bf2-7b1a-44c0-80f9-5b70a3c492c0",
   "metadata": {},
   "source": [
    "# Parameters' study"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 294,
   "id": "e73cb000-0776-4065-b7cd-0b426fe06603",
   "metadata": {},
   "outputs": [],
   "source": [
    "#############################################################################\n",
    "# Analysis on parameters out of multiple runs\n",
    "#############################################################################\n",
    "\n",
    "def parameters_analysis(params, PAR, PARn_str, bounds, timestr, automate, nbins=10, opt_fit=True):\n",
    "    \n",
    "    matrix = np.array(\n",
    "        [\n",
    "            np.array(\n",
    "                [ params[i][j] for i in range(len(params)) ])\n",
    "            for j in range(len(PAR))\n",
    "        ]\n",
    "    )\n",
    "    \n",
    "    PAR_dict = {\n",
    "        r'$A$':         [r'$[-]$',          round(A, 2) ],\n",
    "        r'$B$':         [r'$[-]$',          round(B, 2) ],\n",
    "        r'$C$':         [r'$[dB]$',         round(C, 2) ],\n",
    "        r'$D$':         [r'$[dB m^3/m^3]$', round(D, 2) ],\n",
    "        # r'$\\delta_0$':  [r'$[mm]$',         round(d_0, 2) ],\n",
    "        r'$W_{fc}$':    [r'$[m^3/m^3]$',    round(WW_fc, 2) ],\n",
    "        r'$W_w$':       [r'$[m^3/m^3]$',    round(WW_w, 2) ],\n",
    "        r'$\\rho_{st}$': [r'$[mm/h]$',       round(rho_st, 2) ],\n",
    "        r'$K_{c0}$' :   [r'$[-]$',          round(Kc0, 2)],\n",
    "    }\n",
    "\n",
    "    PARn = []\n",
    "    PARn_dev = []\n",
    "    rowLabels = []\n",
    "    \n",
    "    if automate: opt_save=True\n",
    "    else: opt_save = True if input('Save histograms of params? [y/n]')=='y' else False\n",
    "\n",
    "    for label in PAR_dict:\n",
    "        if label in PARn_str:\n",
    "            i = PARn_str.index(label)\n",
    "            data = matrix[i]\n",
    "            \n",
    "            if len(data)==1:\n",
    "                PARn=[x[0] for x in matrix]\n",
    "                PARn_dev=[0 for x in matrix]\n",
    "            else:\n",
    "                hist_kwargs={'alpha':.5, }\n",
    "                fitline_kwargs={'linestyle':'-',}\n",
    "                counts, bins, pads, popt, pcov, q1, q2, q3, mode = hist_gauss_fit(\n",
    "                    data, nbins=nbins, hist_kwargs=hist_kwargs,\n",
    "                    fitline_kwargs=fitline_kwargs,\n",
    "                    title=f'{label} {PAR_dict[label][0]}', density=True,\n",
    "                    opt_save=opt_save, dir_name=root,\n",
    "                    opt_name=f'{timestr}_hist_{i}',\n",
    "                    opt_fit=opt_fit,\n",
    "                    func=gauss, fit_method='dogbox')\n",
    "                mean=np.mean(data); rang=np.ptp(data)\n",
    "                plt.xlim(mean-rang, mean+rang);\n",
    "                \n",
    "                PARn.append(q2)\n",
    "                PARn_dev.append((q3-q1)/2)\n",
    "                plt.show()\n",
    "\n",
    "            if opt_show: plt.show()\n",
    "            else: plt.close()\n",
    "\n",
    "            PAR_dict[label].pop(1)\n",
    "            PAR_dict[label].append('cal');\n",
    "            PAR_dict[label].append([int(round(bounds[0][i],2)), int(round(bounds[1][i],2))]);\n",
    "            PAR_dict[label].append(round(PARn[i], 3));\n",
    "            PAR_dict[label].append(round(PARn_dev[i], 3));\n",
    "            PAR_dict[label].append(list(matrix[i]));\n",
    "            \n",
    "            if not 'Cal/fix' in rowLabels: rowLabels.append('Cal/fix')\n",
    "            if not 'Bounds' in rowLabels: rowLabels.append('Bounds')\n",
    "            if not 'Median' in rowLabels: rowLabels.append('Median')\n",
    "            if not 'Err' in rowLabels: rowLabels.append('Err')\n",
    "            \n",
    "        else:\n",
    "            PAR_dict[label].append('fix')\n",
    "            PAR_dict[label].append(['/', '/'])\n",
    "            PAR_dict[label].append(PAR_dict[label][1])\n",
    "            PAR_dict[label].append('/')\n",
    "            PAR_dict[label].pop(1)\n",
    "    \n",
    "    print(PAR_dict, '\\n', rowLabels)\n",
    "    return PAR_dict, rowLabels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 295,
   "id": "7065e63f-81c9-4bdb-be32-1caf08ec085c",
   "metadata": {},
   "outputs": [],
   "source": [
    "PAR_dict, rowLabels = parameters_analysis(params, PAR, PARn_str, bounds, timestr, automate, nbins=10, opt_fit=False,)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 296,
   "outputs": [],
   "source": [
    "import json\n",
    "\n",
    "if automate: opt_save=True\n",
    "else: opt_save = True if input('Save log with parameters\\' values? [y/n]')=='y' else False\n",
    "\n",
    "if opt_save:\n",
    "    fname_params = '_params.json'\n",
    "    path_params = root+timestr+fname_params\n",
    "    with open(path_params, 'w') as file: json.dump(PAR_dict, file)\n",
    "    file.close()"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "id": "87c41ed6-0ed3-47db-8377-ecf8e4788048",
   "metadata": {},
   "source": [
    "# Model output - plots sim VS obs for SM, sigma0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 297,
   "id": "aa2d901b-08ff-40fd-8f16-7827ab0aa8dd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Model validation and output\n",
    "\n",
    "if not automate:\n",
    "    if input('Do you want to plot with user-defined parameters\\' values ? [y/n]')=='y':\n",
    "        \n",
    "        timestr = time.strftime(\"%y%m%d-%H%M%S\"); print('Timestring: ', timestr)\n",
    "        \n",
    "        # PAR_tot = [PAR_dict[label][3] for label in PAR_dict]\n",
    "        PAR_tot = [0.329, 0.56, -15, 30, 10, 0.32, 0.10, 0.3, 0.5]\n",
    "        print(PAR_tot)\n",
    "        WW,sigma0,KGE = SWB_WCM_WATERSTEM(PAR_tot, inputs, user_in)\n",
    "    else: WW,sigma0,KGE = SWB_WCM_WATERSTEM(PARn, inputs, user_in) # components = (Ks, rho, depth)\n",
    "\n",
    "else:\n",
    "    PARn = [PAR_dict[label][3] for label in PAR_dict if label in PARn_str]\n",
    "    WW,sigma0,KGE = SWB_WCM_WATERSTEM(PARn, inputs, user_in)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 298,
   "outputs": [],
   "source": [
    "PARn"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 299,
   "id": "3b6c2429-fd5d-4572-bae2-0d8c679705cd",
   "metadata": {},
   "outputs": [],
   "source": [
    "if automate: opt_save_table = True\n",
    "else: opt_save_table = True if input('Save table with machine params? [y/n]')=='y' else False\n",
    "\n",
    "fig, ax = plt.subplots(figsize=(14,5))\n",
    "row_height=0.1; col_width=0.7\n",
    "\n",
    "# Table with machine, inputs params\n",
    "timing = 'daily' if freq=='d' else 'hourly'\n",
    "calib = 'sigma0' if opt_calib=='1' else 'sigma0+sm'\n",
    "cellText = [\n",
    "    # ['Units', units],\n",
    "    # ['Cost function', opt_cost],\n",
    "    # ['Calib on', calib],\n",
    "    ['Optimizer:', optim],\n",
    "    ['Optimizer: options', options],\n",
    "    ['Optimizer: strategy', oh_strategy],\n",
    "    ['N runs, particles, optim. steps', str(len(params))+', '+str(n_particles)+', '+str(n_step)],\n",
    "    # ['Time frequency', timing],\n",
    "    # ['Vegetation descriptor', opt_veg],\n",
    "]\n",
    "table = ax.table(cellText=cellText,\n",
    "                     cellLoc='center', loc='center',\n",
    "                     colLabels=None, rowLabels=None)\n",
    "\n",
    "for (row, col), cell in table.get_celld().items():\n",
    "    cell.set_height(row_height)\n",
    "    cell._loc = 'center'\n",
    "\n",
    "table.auto_set_font_size(False); table.set_fontsize(20)\n",
    "table.auto_set_column_width(col=[x for x in range(len(PAR_dict))])\n",
    "ax.axis('tight'); ax.axis('off')\n",
    "\n",
    "if opt_save_table: plt.savefig(root+timestr+'_table_mach.svg', dpi=100)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 300,
   "id": "e56020d7-32b1-4d81-8fa5-3d01ea34315b",
   "metadata": {},
   "outputs": [],
   "source": [
    "if automate: opt_save_table = True\n",
    "else: opt_save_table = True if input('Save table with params? [y/n]')=='y' else False\n",
    "\n",
    "fig, ax = plt.subplots(figsize=(24,5))\n",
    "row_height=0.1; col_width=0.1\n",
    "\n",
    "single_label = [label for label in PAR_dict][0]\n",
    "cellText = [\n",
    "    [\n",
    "        significant_figures_str(PAR_dict[label][4],PAR_dict[label][i])[1] if (PAR_dict[label][3]=='cal') and (type(PAR_dict[label][i])==float)\n",
    "        else PAR_dict[label][i]\n",
    "        for label in PAR_dict\n",
    "    ] \n",
    "    for i in range(1,1+len(rowLabels))]\n",
    "\n",
    "colLabels = [ f'{label} {PAR_dict[label][0]}' for label in PAR_dict ]\n",
    "# rowLabels = [ 'Guess/fix value', 'Cal/fix', 'Bounds', 'Mean', 'St.dev.']\n",
    "\n",
    "#---------------------------------\n",
    "table = ax.table(cellText=cellText,\n",
    "                 cellLoc='center', loc='center',\n",
    "                 colLabels=colLabels,\n",
    "                 rowLabels=rowLabels,\n",
    "                 )\n",
    "\n",
    "for (row, col), cell in table.get_celld().items():\n",
    "    if row == 0: # or col == 0:\n",
    "        cell.set_text_props(weight='bold')\n",
    "    cell.set_height(row_height)\n",
    "    cell._loc = 'center'\n",
    "\n",
    "table.auto_set_font_size(False); table.set_fontsize(20)\n",
    "table.auto_set_column_width(col=[x for x in range(len(PAR_dict))])\n",
    "ax.axis('tight'); ax.axis('off')\n",
    "\n",
    "if opt_save_table: plt.savefig(root+timestr+'_table.svg')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 301,
   "id": "662e5647-e489-4659-8755-25cba162661b",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyswarms.utils.plotters import plot_cost_history\n",
    "\n",
    "# Obtain cost history from optimizer instance\n",
    "cost_history = optimizer.cost_history\n",
    "\n",
    "# Plot!\n",
    "plot_cost_history(cost_history)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "28035f4c-07ca-43a4-b0c1-17b0d29fbaae",
   "metadata": {},
   "source": [
    "## Plotters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 302,
   "id": "d16a9fb9-31d1-4f3b-9352-3263fc2a2384",
   "metadata": {},
   "outputs": [],
   "source": [
    "#############################################################################\n",
    "# Plotting options (rcParams)\n",
    "#############################################################################\n",
    "\n",
    "rc_dict = {\n",
    "    'axes.titlesize' : 16,\n",
    "    'axes.labelsize' : 16,\n",
    "    # lines.linewidth : 3,\n",
    "    # lines.markersize : 10,\n",
    "    'xtick.labelsize' : 16,\n",
    "    'ytick.labelsize' : 16,\n",
    "    'legend.fontsize' : 'x-large',\n",
    "}\n",
    "    \n",
    "#############################################################################\n",
    "# Triple plot\n",
    "#############################################################################\n",
    "\n",
    "@mplt.rc_context(rc_dict)\n",
    "def plot_triple(fig, ax, times1:list, data1:list, data1_label:str, \n",
    "                input1:list, input1_label:str,\n",
    "                times2:list, data2:list, data2_label:str,\n",
    "                input2:list, input2_label:str,\n",
    "                times3:list, data3:list, data3_label:list,\n",
    "                user_input:list,\n",
    "               ):\n",
    "    \"\"\"3 subplots with 2 sim VS obs timeseries and eventual inputs\n",
    "    \n",
    "    Inputs\n",
    "    ------\n",
    "    - data1: list(obs, sim)\n",
    "    - data1_label: label of the quantity\n",
    "    - input1: list()\n",
    "    - data2: list(obs, sim)\n",
    "    - data2_label: label of the quantity\n",
    "    - input2: list()\n",
    "    - ...\n",
    "    \n",
    "    Note: figure, saving options to be defined outside\n",
    "    \"\"\"\n",
    "    \n",
    "    mplt.rcParams.update(rc_dict)\n",
    "    \n",
    "    #----------------------------------------------------------------------\n",
    "    # Plot 1 sim vs obs timeseries\n",
    "    \n",
    "    obs = data1[0]; obs_label=data1_label+'_obs'\n",
    "    sim = data1[1]; sim_label=data1_label+'_sim'\n",
    "    labely = data1_label\n",
    "    times = times1\n",
    "    marker='o'; linestyle='-'\n",
    "    units=r' $[dB]$'\n",
    "    \n",
    "    # RMSE, R, bias, KGE calculation\n",
    "    RMSE=np.mean((sim-obs)**2)**0.5; print('RMSE =', RMSE)\n",
    "    R=np.corrcoef(sim,obs)[0][1]; print('R=', R)\n",
    "    BIAS=bias(sim,obs); print('bias =', BIAS)\n",
    "    KGE=he.evaluator(he.kge, sim, obs)[0,:][0]; print('KGE=', KGE)\n",
    "    \n",
    "    title=f'{sim_label} VS {obs_label} - RMSE={RMSE:.2f}, R={R:.2f}, bias={BIAS:.2f}, KGE={KGE:.2f}'\n",
    "    \n",
    "    ax[0].set_xlim(xmin=times[0], xmax=times[len(times)-1])\n",
    "    ax[0].plot(times, sim, c='tab:red', label=sim_label,\n",
    "               linestyle=linestyle, lw=1, marker=marker, ms=1)#alpha=.4, zorder=-1)\n",
    "    ax[0].plot(times, obs, c='tab:blue', label=obs_label,\n",
    "               linestyle=linestyle, lw=1, marker=marker, ms=1,\n",
    "               alpha=.4, zorder=-1)\n",
    "    ax[0].legend(loc='upper left')\n",
    "    ax[0].set_title(title)\n",
    "    ax[0].set_ylabel(labely+units, size='xx-large')\n",
    "    \n",
    "    units = r' $[-]$'\n",
    "    ax0 = ax[0].twinx()\n",
    "    ax0.plot(times, input1, label=input1_label, color='tab:green', lw=1)\n",
    "    ax0.legend(loc='upper right')\n",
    "    ax0.set_ylabel(input1_label+units, size='xx-large')\n",
    "    \n",
    "    \n",
    "    #-----------------------------------------------------------------------\n",
    "    # Plot 2 sim vs obs timeseries\n",
    "    \n",
    "    sim = data2[0]; sim_label=data2_label+'_sim'\n",
    "    labely = data2_label\n",
    "    times = times2\n",
    "    units = r' $[m^3/m^3]$'\n",
    "    \n",
    "    title=f'{sim_label}'\n",
    "    \n",
    "    ax[1].set_xlim(xmin=times[0], xmax=times[-1])\n",
    "    ax[1].plot(times, sim, c='tab:red', label=sim_label)\n",
    "    ax[1].legend(loc='upper left')\n",
    "    ax[1].set_title(title)\n",
    "    ax[1].set_ylabel(data2_label+units, size='xx-large')\n",
    "    \n",
    "    #-----------------------------------------------------------------------\n",
    "    # Plot of inputs P, EPOT\n",
    "    \n",
    "    label1, label2 = data3_label\n",
    "    times = times3\n",
    "    units = r' $[mm]$'\n",
    "    \n",
    "    ax[2].bar(times, data3[0], color='tab:gray', label=label1, )\n",
    "    ax[2].legend(loc='upper left')\n",
    "    ax[2].set_ylabel(label1+', '+label2+units, size='xx-large')\n",
    "    \n",
    "    ax2 = ax[2].twinx()\n",
    "    ax2.plot(times, data3[1], label=label2, color='tab:green')\n",
    "    ax2.legend(loc='upper right')\n",
    "    ax2.set_ylabel(label2+r' $[mm/h]$', size='xx-large')\n",
    "    \n",
    "    \n",
    "    #-----------------------------------------------------------------------\n",
    "    \n",
    "    ax[0].set_ylim(-18, -7)\n",
    "    ax0.set_ylim(0, 1)\n",
    "    ax[1].set_ylim(0, .5)\n",
    "    ax[2].set_ylim(0, 100)\n",
    "    ax2.set_ylim(0, 10)    \n",
    "        \n",
    "        \n",
    "#############################################################################\n",
    "# Scatter plot\n",
    "#############################################################################\n",
    "\n",
    "def plot_sim_vs_obs(sim:list, obs:list, quantity:str, um:str):\n",
    "    \n",
    "    import matplotlib.gridspec as gridspec\n",
    "    \n",
    "    def linear(x,a,b):\n",
    "        return a+b*x\n",
    "    \n",
    "    title = f'{quantity} obs VS simul - ' # y VS x\n",
    "    xlabel = f'{quantity}_sim {um}'\n",
    "    ylabel = f'{quantity}_obs {um}'\n",
    "    \n",
    "    data = pd.DataFrame({'sim': sim,'obs': obs})\n",
    "    data.dropna(inplace=True)\n",
    "    x = data.sim.values\n",
    "    y = data.obs.values\n",
    "    \n",
    "    fig = plt.figure(figsize=(6, 6), dpi=200)\n",
    "    gs = gridspec.GridSpec(nrows=1, ncols=1, width_ratios=[1], height_ratios=[1])\n",
    "    ax = plt.subplot(gs[0])\n",
    "    ax.plot(x, y, marker='o', linestyle='', color='tab:blue')\n",
    "    min_common = np.min([x,y])-0.1*abs(np.mean([x,y]))\n",
    "    max_common = np.max([x,y])+0.1*abs(np.mean([x,y]))\n",
    "    ax.set_xlim(min_common, max_common)\n",
    "    ax.set_ylim(min_common, max_common)\n",
    "    lin_grid = np.linspace(ax.get_xlim()[0], ax.get_xlim()[1], 100); # ax.plot(lin_grid, lin_grid, color='k') # y = x\n",
    "    \n",
    "    # Fit\n",
    "    popt, pcov = curve_fit(linear, x, y)\n",
    "    ax.plot(lin_grid, linear(np.array(lin_grid),*popt), color='k')\n",
    "    \n",
    "    RMSE=np.nanmean((sim-obs)**2)**0.5; print('RMSE =', RMSE)\n",
    "    R=np.corrcoef(x,y)[0][1]; print('R=', R, 'R^2=', R**2)\n",
    "    BIAS=bias(x,y); print('bias=', BIAS)\n",
    "    \n",
    "    ax.set_xlabel(xlabel); ax.set_ylabel(ylabel)\n",
    "    xtext=0.2*(max_common-min_common)+min_common\n",
    "    ytext=0.9*(max_common-min_common)+min_common\n",
    "    ax.text(xtext, ytext,\n",
    "            f'y={popt[0]:.2f}+{popt[1]:.2f}x',\n",
    "            ha=\"center\", va=\"center\", size=15,\n",
    "            bbox=dict(boxstyle=\"round,pad=0.3\", fc=\"w\", ec=\"k\", lw=2, alpha=.5))\n",
    "    \n",
    "    ax.set_title(title+f'RMSE={RMSE:.2f}, R={R:.2f},'+r' $R^2$'+f'={R**2:.2f}, bias={BIAS:.2f}')\n",
    "    ax.set_aspect('equal', adjustable='box', share=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 303,
   "id": "f1011469-3838-4aef-a0f4-357859d0f941",
   "metadata": {},
   "outputs": [],
   "source": [
    "#####################################################################\n",
    "# Triple plot\n",
    "#####################################################################\n",
    "opt_show=True    \n",
    "from scipy.signal import savgol_filter\n",
    "        \n",
    "if automate: opt_save = True\n",
    "else: opt_save = True if input('Save triple plot SM+s0+inputs? [y/n]')=='y' else False\n",
    "\n",
    "fig, ax = plt.subplots(3, 1,constrained_layout=False,figsize=(14, 12), sharex=True,dpi=300,)\n",
    "\n",
    "\n",
    "filename = f'_triple'+PAR_str_add\n",
    "from scipy.signal import savgol_filter\n",
    "\n",
    "plot_triple(fig, ax,\n",
    "            times1=t_sat, data1=[s0, sigma0], data1_label=r'$\\sigma^0$', \n",
    "            input1=veg, input1_label='NDVI',\n",
    "            times2=t, data2=[WW], data2_label=r'SM',\n",
    "            input2=[], input2_label='',\n",
    "            times3=t, data3=\n",
    "            [P, EPOT],\n",
    "            data3_label=['Rain', 'mean ET0'],\n",
    "            user_input=[''],\n",
    "           )\n",
    "\n",
    "for axi in ax:\n",
    "    axi.set_xlim(xmin=t_sat[0], xmax=t_sat[-1])\n",
    "    axi.tick_params(axis='both', labelsize=16)\n",
    "    plt.setp(axi.get_xticklabels(), rotation=45, ha=\"right\",\n",
    "         rotation_mode=\"anchor\")\n",
    "\n",
    "name=''\n",
    "if opt_save:\n",
    "    optim_choice = 'glo' if (optim=='')or(optim=='global') else 'local'\n",
    "    plt.savefig(root+timestr+filename+'.svg')\n",
    "\n",
    "if opt_show: plt.show()\n",
    "plt.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 304,
   "outputs": [],
   "source": [
    "min(WW)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "id": "e90b1a6e-6dd2-4d4f-b137-d48a1f96d167",
   "metadata": {},
   "source": [
    "## Scatterplot"
   ],
   "outputs": [],
   "execution_count": 305
  },
  {
   "cell_type": "raw",
   "source": [
    "if automate: opt_save = True\n",
    "else: opt_save = True if input('Save scatterplot of SM? [y/n]')=='y' else False\n",
    "\n",
    "filename = f'scatter_'+'sigma0_'+units+PAR_str_add # 'sigma0'\n",
    "\n",
    "plot_sim_vs_obs(sim=sigma0, obs=s0, quantity=r'$\\sigma^0$', um='[dB]')\n",
    "    \n",
    "if opt_save: plt.savefig('Plot\\\\'+timestr+'_'+filename+'.svg')"
   ],
   "metadata": {
    "collapsed": false
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python (satellite)",
   "language": "python",
   "name": "satellite"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
